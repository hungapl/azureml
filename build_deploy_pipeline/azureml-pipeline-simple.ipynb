{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning Service example\n",
    "### Deploy and publish scoring pipeline\n",
    "\n",
    "*This notebook shows you how to:*\n",
    "- Build a pipeline using ParallelRunStep or PythonScriptStep\n",
    "- Publish pipeline\n",
    "- Deploy the pipelie as REST end point\n",
    "- Request to score via the HTTP endpoint with basic authentication\n",
    "\n",
    "There is a similar [tutorial](https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-pipeline-batch-scoring-classification) in Azure documentation, but this example uses a simpler problem which is faster to run without using tensorflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup workspace\n",
    "- Workspace created in Azure Machine Learning service - [howto](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace?tabs=python)\n",
    "- Updated the cell below with your workspace details and run the cell to connect to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "config_file = '_config.json'\n",
    "\n",
    "subscription_id='xxxxx' # Subscription ID of the workspace\n",
    "resource_group='xxxxx' # Resource group of the workspace\n",
    "workspace_name = \"xxxxxx\" # Name of your workspace\n",
    "\n",
    "if os.path.isfile(config_file):\n",
    "    with open(config_file, 'r') as f:\n",
    "        configs = json.load(f)\n",
    "        subscription_id = configs['subscription_id']\n",
    "        resource_group = configs['resource_group']\n",
    "        workspace_name = configs['workspace_name']\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.get(name=workspace_name,\n",
    "               subscription_id=subscription_id,\n",
    "               resource_group=resource_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise\n",
    "- Updated the asset names in the cell below (optional)\n",
    "- Execute to initialise variables, create temp directory for storing files for upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.20.0\n"
     ]
    }
   ],
   "source": [
    "# Asset names \n",
    "model_dir = 'simple_model'\n",
    "model_name = model_dir\n",
    "model_file = 'model_v{}.json'\n",
    "experiment_name = \"pipeline_simple\"\n",
    "compute_name = \"DS3-4c-14G\"\n",
    "environment_name = \"test_minimal\"\n",
    "dataset_parent_path = \"data\"\n",
    "dataset_name = experiment_name\n",
    "\n",
    "# Temp local directory for storing created files that will be uploaded to AML for the pipeline\n",
    "local_temp_dir = './_temp'\n",
    "\n",
    "import os \n",
    "local_path_to_model = os.path.join(local_temp_dir, model_dir)\n",
    "if not os.path.isdir(local_path_to_model):\n",
    "    os.makedirs(local_path_to_model)\n",
    "    \n",
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Dataset\n",
    "1. Generate sample input dataset csv file by executing the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./_temp/pipeline_simple_input.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./_temp/pipeline_simple_input.csv\n",
    "id,gender,age\n",
    "1,F,30\n",
    "2,F,50\n",
    "3,M,55\n",
    "4,M,23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the Azure ML web interface to register the dataset\n",
    "    - Load your AML workspace in the web browser\n",
    "    - Click on 'Dataset' option\n",
    "    - Use the register action to register this input csv as a dataset in your workspace, use the name 'pipeline_simple' as the dataset name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reference to input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset \n",
    "input_data = Dataset.get_by_name(ws, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and register model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age_average': 40}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Create model\n",
    "class MyModel:\n",
    "    \n",
    "    def load_model(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            loaded_params = json.load(f)\n",
    "            return MyModel(loaded_params)\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self._params = params\n",
    "    \n",
    "    def predict(self, data):\n",
    "        data['prediction'] = data.age < self._params['age_average']\n",
    "        return data[['id', 'prediction']]\n",
    "\n",
    "    \n",
    "\n",
    "params = {'age_average':40}\n",
    "local_model_path = os.path.join(local_path_to_model, model_file)\n",
    "\n",
    "with open(local_model_path, 'w') as f:\n",
    "    json.dump(params, f)\n",
    "# Test model code\n",
    "mymodel = MyModel.load_model(local_model_path)\n",
    "print(str(mymodel._params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "\n",
    "# checks to see if compute target already exists in workspace, else create it\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
    "except ComputeTargetException as e:\n",
    "    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\",\n",
    "                                                   vm_priority=\"lowpriority\", \n",
    "                                                   min_nodes=0, \n",
    "                                                   max_nodes=1)\n",
    "\n",
    "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define environment\n",
    "- Create requirements file with dependencies require for running your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./_temp/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./_temp/requirements.txt\n",
    "pandas\n",
    "numpy\n",
    "azureml-core\n",
    "azureml-dataset-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "# Pipeline doesn't like using curated environment, create a new one \n",
    "env = Environment.from_pip_requirements(name = environment_name, file_path = os.path.join(local_temp_dir, 'requirements.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build & run pipeline\n",
    "#### 1. Create scoring file\n",
    "This is a python script for making prediction based on your model.  This [section](https://docs.microsoft.com/en-au/azure/machine-learning/how-to-deploy-existing-model#entry-script-scorepy) in Azure documentation explains how this file works.  Note how this scoring script uses azureml.core modules, hence we need the azureml-core azure-datatime-runtime included as dependencies when defining the environment previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./_temp/scoring.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./_temp/scoring.py\n",
    "\n",
    "from azureml.core import Run\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    \n",
    "    class MyModel:\n",
    "\n",
    "        def load_model(file_path):\n",
    "            with open(file_path, 'r') as f:\n",
    "                loaded_params = json.load(f)\n",
    "                return MyModel(loaded_params)\n",
    "\n",
    "        def __init__(self, params):\n",
    "            self._params = params\n",
    "\n",
    "        def predict(self, data):\n",
    "            data['prediction'] = data.age < self._params['age_average']\n",
    "            return data[['id', 'prediction']]\n",
    "        \n",
    "    # Read from parameters from argument, e.g. which model to use\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    \n",
    "    model_dir = 'simple_model'\n",
    "    model_name = args.model_name\n",
    "    print(str(datetime.now()) + ': init()')\n",
    "\n",
    "    model_path = Model.get_model_path(model_dir) + '/' + model_name + '.json'\n",
    "    model = MyModel.load_model(model_path)\n",
    "    print(str(datetime.now()) + ': Model loaded')\n",
    "\n",
    "\n",
    "def run(data):\n",
    "    print(str(datetime.now()) + ': run()')\n",
    "    output = model.predict(data)\n",
    "    print(str(datetime.now()) + ': run completed()')\n",
    "    return output\n",
    "\n",
    "def local_test():\n",
    "    init()\n",
    "    input_data = pd.read_csv(os.path.join('_temp/pipeline_simple_input.csv'))\n",
    "    print(run(input_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define the pipeline\n",
    "- Here, we are building a pipeline with only one step.  A pipeline can contain multiple steps that perform post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PythonScriptStep' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ec14d344900b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m                              \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                              source_directory=\".\")\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mscore_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_step_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-ec14d344900b>\u001b[0m in \u001b[0;36mpython_step_step\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpython_step_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     return PythonScriptStep(script_name=score_script,\n\u001b[0m\u001b[1;32m     43\u001b[0m                              \u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"--model_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name_param\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                              \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PythonScriptStep' is not defined"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter\n",
    "\n",
    "def_data_store = Datastore.get_default(ws)\n",
    "score_script = os.path.join(local_temp_dir, \"scoring.py\")\n",
    "\n",
    "def parallel_run_step():\n",
    "    from azureml.pipeline.steps import ParallelRunConfig\n",
    "    from azureml.pipeline.core import PipelineData\n",
    "\n",
    "    parallel_run_config = ParallelRunConfig(\n",
    "        environment=env,\n",
    "        entry_script=score_script,\n",
    "        source_directory=\".\",\n",
    "        output_action=\"append_row\",\n",
    "        append_row_file_name=\"parallel_run_step.txt\",\n",
    "        compute_target=compute_target,\n",
    "        error_threshold=1,\n",
    "        node_count=1,\n",
    "        process_count_per_node=2\n",
    "    )\n",
    "\n",
    "    from azureml.pipeline.steps import ParallelRunStep\n",
    "    from datetime import datetime\n",
    "\n",
    "    parallel_step_name = \"scoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "    output_dir = PipelineData(name=dataset_name, datastore=def_data_store)\n",
    "    model_name_param = PipelineParameter(name=\"model_arg\", default_value=model_name)\n",
    "\n",
    "    score_step = ParallelRunStep(\n",
    "        name=parallel_step_name,\n",
    "        inputs=[input_data.as_named_input(\"input\")],\n",
    "        output=output_dir,\n",
    "        arguments=[\"--model_name\", model_name_param],\n",
    "        parallel_run_config=parallel_run_config,\n",
    "        allow_reuse=False\n",
    "    )\n",
    "    return score_step\n",
    "\n",
    "def python_step_step():\n",
    "    return PythonScriptStep(script_name=score_script,\n",
    "                             arguments=[\"--model_name\", model_name_param],\n",
    "                             target=compute_target,\n",
    "                             source_directory=\".\")\n",
    "score_step = python_step_step()\n",
    "pipeline = Pipeline(workspace=ws, steps=[score_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Submit the pipeline as an experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "pipeline_run = Experiment(ws, experiment_name).submit(pipeline)\n",
    "print(pipeline_run)\n",
    "pipeline_run.wait_for_completion(show_output=True)\n",
    "print('Completed in {}'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish pipeline as a REST endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=experiment_name, description=\"scoring\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a job via REST endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name,\n",
    "                               \"ParameterAssignments\": {\"model_name\": model_name}})\n",
    "try:\n",
    "    response.raise_for_status()\n",
    "except Exception:    \n",
    "    raise Exception(\"Received bad response from the endpoint: {}\\n\"\n",
    "                    \"Response Code: {}\\n\"\n",
    "                    \"Headers: {}\\n\"\n",
    "                    \"Content: {}\".format(rest_endpoint, response.status_code, response.headers, response.content))\n",
    "\n",
    "run_id = response.json().get('Id')\n",
    "print('Submitted pipeline run: ', run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
