{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning Service example\n",
    "### Deploy and publish scoring pipeline\n",
    "\n",
    "*This notebook shows you how to:*\n",
    "- Build a pipeline using ParallelRunStep or PythonScriptStep\n",
    "- Publish pipeline\n",
    "- Deploy the pipelie as REST end point\n",
    "- Request to score via the HTTP endpoint with basic authentication\n",
    "\n",
    "These similar to [tutorial](https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-pipeline-batch-scoring-classification) published in Microsoft documentation.  \n",
    "\n",
    "Difference between the existing batch scoring example and this example:\n",
    "\n",
    "- This version focus in demonstrating the code for the pipeline using a simple problem\n",
    "- It is much easier to register and configure the assets (e.g. Dataset, Compute) through the Azure Machine Learning Service web interface, so the assumption is that they have already been created and the pipeline code will use **get** instead of **register** to get references to those assets in your workspace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup workspace\n",
    "- Workspace created in Azure Machine Learning service - [howto](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace?tabs=python)\n",
    "- Updated the cell below with your workspace details and run the cell to connect to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "config_file = '_config.json'\n",
    "\n",
    "subscription_id='xxxxx' # Subscription ID of the workspace\n",
    "resource_group='xxxxx' # Resource group of the workspace\n",
    "workspace_name = \"xxxxxx\" # Name of your workspace\n",
    "\n",
    "if os.path.isfile(config_file):\n",
    "    with open(config_file, 'r') as f:\n",
    "        configs = json.load(f)\n",
    "        subscription_id = configs['subscription_id']\n",
    "        resource_group = configs['resource_group']\n",
    "        workspace_name = configs['workspace_name']\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.get(name=workspace_name,\n",
    "               subscription_id=subscription_id,\n",
    "               resource_group=resource_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise\n",
    "- Updated the asset names in the cell below (optional)\n",
    "- Execute to initialise variables, create temp directory for storing files for upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.20.0\n"
     ]
    }
   ],
   "source": [
    "# Asset names \n",
    "model_dir = 'simple_model'\n",
    "model_name = model_dir\n",
    "model_file = 'model_v{}.json'\n",
    "experiment_name = \"pipeline_simple\"\n",
    "compute_name = \"DS3-4c-14G\"\n",
    "environment_name = \"test_minimal\"\n",
    "dataset_parent_path = \"data\"\n",
    "dataset_name = experiment_name\n",
    "\n",
    "# Temp local directory for storing created files that will be uploaded to AML for the pipeline\n",
    "local_temp_dir = './_temp'\n",
    "\n",
    "import os \n",
    "local_path_to_model = os.path.join(local_temp_dir, model_dir)\n",
    "if not os.path.isdir(local_path_to_model):\n",
    "    os.makedirs(local_path_to_model)\n",
    "    \n",
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Dataset\n",
    "1. Generate sample input dataset csv file by executing the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./_temp/pipeline_simple_input.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./_temp/pipeline_simple_input.csv\n",
    "id,gender,age\n",
    "1,F,30\n",
    "2,F,50\n",
    "3,M,55\n",
    "4,M,23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the Azure ML web interface to register the dataset\n",
    "    - Load your AML workspace in the web browser\n",
    "    - Click on 'Dataset' option\n",
    "    - Use the register action to register this input csv as a dataset in your workspace, use the name 'pipeline_simple' as the dataset name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reference to input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset \n",
    "input_data = Dataset.get_by_name(ws, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and register model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age_average': 40}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Create model\n",
    "class MyModel:\n",
    "    \n",
    "    def load_model(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            loaded_params = json.load(f)\n",
    "            return MyModel(loaded_params)\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self._params = params\n",
    "    \n",
    "    def predict(self, data):\n",
    "        data['prediction'] = data.age < self._params['age_average']\n",
    "        return data[['id', 'prediction']]\n",
    "\n",
    "    \n",
    "\n",
    "params = {'age_average':40}\n",
    "local_model_path = os.path.join(local_path_to_model, model_file)\n",
    "\n",
    "with open(local_model_path, 'w') as f:\n",
    "    json.dump(params, f)\n",
    "# Test model code\n",
    "mymodel = MyModel.load_model(local_model_path)\n",
    "print(str(mymodel._params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "\n",
    "# checks to see if compute target already exists in workspace, else create it\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
    "except ComputeTargetException as e:\n",
    "    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\",\n",
    "                                                   vm_priority=\"lowpriority\", \n",
    "                                                   min_nodes=0, \n",
    "                                                   max_nodes=1)\n",
    "\n",
    "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define environment\n",
    "- Create requirements file with dependencies require for running your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./_temp/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./_temp/requirements.txt\n",
    "pandas\n",
    "numpy\n",
    "azureml-core\n",
    "azureml-dataset-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "# Pipeline doesn't like using curated environment, create a new one \n",
    "env = Environment.from_pip_requirements(name = environment_name, file_path = os.path.join(local_temp_dir, 'requirements.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build & run pipeline\n",
    "#### 1. Create scoring file\n",
    "This is a python script for making prediction based on your model.  This [section](https://docs.microsoft.com/en-au/azure/machine-learning/how-to-deploy-existing-model#entry-script-scorepy) in Azure documentation explains how this file works.  Note how this scoring script uses azureml.core modules, hence we need the azureml-core azure-datatime-runtime included as dependencies when defining the environment previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./_temp/batch_scoring.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./_temp/scoring.py\n",
    "\n",
    "from azureml.core import Run\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    \n",
    "    class MyModel:\n",
    "\n",
    "        def load_model(file_path):\n",
    "            with open(file_path, 'r') as f:\n",
    "                loaded_params = json.load(f)\n",
    "                return MyModel(loaded_params)\n",
    "\n",
    "        def __init__(self, params):\n",
    "            self._params = params\n",
    "\n",
    "        def predict(self, data):\n",
    "            data['prediction'] = data.age < self._params['age_average']\n",
    "            return data[['id', 'prediction']]\n",
    "        \n",
    "    # Read from parameters from argument, e.g. which model to use\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    \n",
    "    model_dir = 'simple_model'\n",
    "    model_name = args.model_name\n",
    "    print(str(datetime.now()) + ': init()')\n",
    "\n",
    "    model_path = Model.get_model_path(model_dir) + '/' + model_name + '.json'\n",
    "    model = MyModel.load_model(model_path)\n",
    "    print(str(datetime.now()) + ': Model loaded')\n",
    "\n",
    "\n",
    "def run(data):\n",
    "    print(str(datetime.now()) + ': run()')\n",
    "    output = model.predict(data)\n",
    "    print(str(datetime.now()) + ': run completed()')\n",
    "    return output\n",
    "\n",
    "def local_test():\n",
    "    init()\n",
    "    input_data = pd.read_csv(os.path.join('_temp/pipeline_simple_input.csv'))\n",
    "    print(run(input_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define the pipeline\n",
    "- Here, we are building a pipeline with only one step.  A pipeline can contain multiple steps that perform post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/azureml/pipeline/core/_parallel_run_step_base.py:508: UserWarning: \n",
      "ParallelRunStep requires azureml-dataset-runtime[fuse,pandas] for tabular dataset.\n",
      "Please add relevant package in CondaDependencies.\n",
      "  Please add relevant package in CondaDependencies.\"\"\".format(extra, self._input_ds_type), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter\n",
    "\n",
    "def_data_store = Datastore.get_default(ws)\n",
    "score_script = os.path.join(local_temp_dir, \"scoring.py\")\n",
    "\n",
    "def parallel_run_step():\n",
    "    from azureml.pipeline.steps import ParallelRunConfig\n",
    "    from azureml.pipeline.core import PipelineData\n",
    "\n",
    "    parallel_run_config = ParallelRunConfig(\n",
    "        environment=env,\n",
    "        entry_script=score_script,\n",
    "        source_directory=\".\",\n",
    "        output_action=\"append_row\",\n",
    "        append_row_file_name=\"parallel_run_step.txt\",\n",
    "        compute_target=compute_target,\n",
    "        error_threshold=1,\n",
    "        node_count=1,\n",
    "        process_count_per_node=2\n",
    "    )\n",
    "\n",
    "    from azureml.pipeline.steps import ParallelRunStep\n",
    "    from datetime import datetime\n",
    "\n",
    "    parallel_step_name = \"scoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "    output_dir = PipelineData(name=dataset_name, datastore=def_data_store)\n",
    "    model_name_param = PipelineParameter(name=\"model_arg\", default_value=model_name)\n",
    "\n",
    "    score_step = ParallelRunStep(\n",
    "        name=parallel_step_name,\n",
    "        inputs=[input_data.as_named_input(\"input\")],\n",
    "        output=output_dir,\n",
    "        arguments=[\"--model_name\", model_name_param],\n",
    "        parallel_run_config=parallel_run_config,\n",
    "        allow_reuse=False\n",
    "    )\n",
    "    return score_step\n",
    "\n",
    "def python_step_step():\n",
    "    return PythonScriptStep(script_name=score_script,\n",
    "                             arguments=arguments=[\"--model_name\", model_name_param],\n",
    "                             target=compute_target,\n",
    "                             source_directory=\".\")\n",
    "score_step = parallel_run_step()\n",
    "pipeline = Pipeline(workspace=ws, steps=[score_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Submit the pipeline as an experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batchscoring-202101151600 [7d1d18b8][6cf11253-38c3-4064-8892-1fc492853955], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 0fc7480b-06ae-4643-a05f-d8e9ad0d18c7\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/pipeline_simple/runs/0fc7480b-06ae-4643-a05f-d8e9ad0d18c7?wsid=/subscriptions/2643b3a6-256f-49a8-81a2-16283d061433/resourcegroups/azuremltest/workspaces/hungap_test_2021\n",
      "Run(Experiment: pipeline_simple,\n",
      "Id: 0fc7480b-06ae-4643-a05f-d8e9ad0d18c7,\n",
      "Type: azureml.PipelineRun,\n",
      "Status: Running)\n",
      "PipelineRunId: 0fc7480b-06ae-4643-a05f-d8e9ad0d18c7\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/pipeline_simple/runs/0fc7480b-06ae-4643-a05f-d8e9ad0d18c7?wsid=/subscriptions/2643b3a6-256f-49a8-81a2-16283d061433/resourcegroups/azuremltest/workspaces/hungap_test_2021\n",
      "PipelineRun Status: Running\n",
      "\n",
      "\n",
      "StepRunId: 0955963e-984b-4d67-bb42-88de845e1f57\n",
      "Link to Azure Machine Learning Portal: https://ml.azure.com/experiments/pipeline_simple/runs/0955963e-984b-4d67-bb42-88de845e1f57?wsid=/subscriptions/2643b3a6-256f-49a8-81a2-16283d061433/resourcegroups/azuremltest/workspaces/hungap_test_2021\n",
      "StepRun( batchscoring-202101151600 ) Status: NotStarted\n",
      "StepRun( batchscoring-202101151600 ) Status: Running\n",
      "\n",
      "Streaming azureml-logs/55_azureml-execution-tvmps_254caf111fca5ea9768480baf7421c59a2a87174afc300de44eb1d1f8ee51319_d.txt\n",
      "========================================================================================================================\n",
      "2021-01-15T06:01:43Z Starting output-watcher...\n",
      "2021-01-15T06:01:43Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
      "2021-01-15T06:01:44Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
      "2021-01-15T06:01:44Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
      ">>>   \n",
      ">>>   \n",
      "Login Succeeded\n",
      "Using default tag: latest\n",
      "latest: Pulling from azureml/azureml_1a8de9df2498c9299310332ad87a7807\n",
      "Digest: sha256:ae85781838cbc95b91919615bb572a65492e7640baa36f7d8104c25e05b5ab55\n",
      "Status: Image is up to date for ngiotedge.azurecr.io/azureml/azureml_1a8de9df2498c9299310332ad87a7807:latest\n",
      "ngiotedge.azurecr.io/azureml/azureml_1a8de9df2498c9299310332ad87a7807:latest\n",
      "2021-01-15T06:01:46Z Check if container 0955963e-984b-4d67-bb42-88de845e1f57 already exist exited with 0, \n",
      "\n",
      "92065e295bdde2ffb68cf1cd35735e6e88e89dd83db2ad50c5c994d7e387060e\n",
      "2021/01/15 06:01:48 Starting App Insight Logger for task:  containerSetup\n",
      "2021/01/15 06:01:48 Version: 3.0.01467.0002 Branch: 70 Commit: 969f819\n",
      "2021/01/15 06:01:48 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/01/15 06:01:48 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
      "2021/01/15 06:01:48 sshd inside container not required for job, skipping setup.\n",
      "2021/01/15 06:01:48 All App Insights Logs was send successfully\n",
      "2021-01-15T06:01:48Z Starting docker container succeeded.\n",
      "\n",
      "Streaming azureml-logs/70_driver_log.txt\n",
      "========================================\n",
      "2021/01/15 06:02:05 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n",
      "2021/01/15 06:02:05 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "[2021-01-15T06:02:06.450460] Entering context manager injector.\n",
      "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['driver/amlbi_main.py', '--client_sdk_version', '1.20.0', '--scoring_module_name', './_temp/batch_scoring.py', '--mini_batch_size', '1048576', '--error_threshold', '1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'parallel_run_step.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/hungap_test_2021/azureml/0955963e-984b-4d67-bb42-88de845e1f57/mounts/workspaceblobstore/azureml/0955963e-984b-4d67-bb42-88de845e1f57/pipeline_simple', '--process_count_per_node', '2', '--model_name', 'simple_model', '--input_ds_0', 'input'])\n",
      "Script type = None\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 98\n",
      "Entering Run History Context Manager.\n",
      "[2021-01-15T06:02:09.207765] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/hungap_test_2021/azureml/0955963e-984b-4d67-bb42-88de845e1f57/mounts/workspaceblobstore/azureml/0955963e-984b-4d67-bb42-88de845e1f57\n",
      "[2021-01-15T06:02:09.208017] Preparing to call script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.20.0', '--scoring_module_name', './_temp/batch_scoring.py', '--mini_batch_size', '1048576', '--error_threshold', '1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'parallel_run_step.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/hungap_test_2021/azureml/0955963e-984b-4d67-bb42-88de845e1f57/mounts/workspaceblobstore/azureml/0955963e-984b-4d67-bb42-88de845e1f57/pipeline_simple', '--process_count_per_node', '2', '--model_name', 'simple_model', '--input_ds_0', 'input']\n",
      "[2021-01-15T06:02:09.208100] After variable expansion, calling script [driver/amlbi_main.py] with arguments:['--client_sdk_version', '1.20.0', '--scoring_module_name', './_temp/batch_scoring.py', '--mini_batch_size', '1048576', '--error_threshold', '1', '--output_action', 'append_row', '--logging_level', 'INFO', '--run_invocation_timeout', '60', '--run_max_try', '3', '--create_snapshot_at_runtime', 'True', '--append_row_file_name', 'parallel_run_step.txt', '--output', '/mnt/batch/tasks/shared/LS_root/jobs/hungap_test_2021/azureml/0955963e-984b-4d67-bb42-88de845e1f57/mounts/workspaceblobstore/azureml/0955963e-984b-4d67-bb42-88de845e1f57/pipeline_simple', '--process_count_per_node', '2', '--model_name', 'simple_model', '--input_ds_0', 'input']\n",
      "\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 98\n",
      "\n",
      "\n",
      "[2021-01-15T06:07:40.911339] The experiment failed. Finalizing run...\n",
      "Cleaning up all outstanding Run operations, waiting 900.0 seconds\n",
      "3 items cleaning up...\n",
      "Cleanup took 0.17115116119384766 seconds\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 98\n",
      "azureml_common.parallel_run.exception_info.Exception: Run failed. Below is the error detail:\n",
      "EntryScriptException: Entry script error. No progress update in 270 seconds. No progress update in this check. Wait 274 seconds since last update. Remain 0 seconds to progress timeout. 0 among 1 mini batches processed. Please check logs/user/error/* and logs/sys/error/* to see if some errors have occurred.\n",
      "No mini batch has been processed.\n",
      "The init() function in the entry script had raised exception for 6 times. Please check logs at logs/user/error/* for details.\n",
      "  * Error '[Errno 20] Not a directory: 'azureml-models/simple_model/8/simple_model/model1.json/simple_model.json'' occurred 6 times.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"driver/amlbi_main.py\", line 136, in <module>\n",
      "    main()\n",
      "  File \"driver/amlbi_main.py\", line 113, in main\n",
      "    boot(driver_dir)\n",
      "  File \"driver/amlbi_main.py\", line 54, in boot\n",
      "    booter.start()\n",
      "  File \"driver/azureml_user/parallel_run/boot.py\", line 299, in start\n",
      "    self.start_sys_main()\n",
      "  File \"driver/azureml_user/parallel_run/boot.py\", line 206, in start_sys_main\n",
      "    self.run(cmd)\n",
      "  File \"driver/azureml_user/parallel_run/boot.py\", line 161, in run\n",
      "    BootResult().check_result(stdout)\n",
      "  File \"driver/azureml_user/parallel_run/boot_result.py\", line 36, in check_result\n",
      "    raise Exception(message) from cause\n",
      "Exception: Run failed, please check logs for details. You can check logs/readme.txt for the layout of logs.\n",
      "\n",
      "[2021-01-15T06:07:41.287432] Finished context manager injector with Exception.\n",
      "2021/01/15 06:07:41 Failed to parse control script error: /mnt/batch/tasks/workitems/a36d9159-d2d0-48c1-89da-ad7cc61b4ce1/job-1/0955963e-984b-4d67-b_90cd3c17-76e8-48b6-be16-3b52b7ccfd03/wd/runTaskLetTask_error.json to json File /mnt/batch/tasks/workitems/a36d9159-d2d0-48c1-89da-ad7cc61b4ce1/job-1/0955963e-984b-4d67-b_90cd3c17-76e8-48b6-be16-3b52b7ccfd03/wd/runTaskLetTask_error.json doesn't exist\n",
      "2021/01/15 06:07:41 Failed to run the wrapper cmd with err: exit status 1\n",
      "2021/01/15 06:07:41 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
      "2021/01/15 06:07:41 mpirun version string: {\n",
      "Intel(R) MPI Library for Linux* OS, Version 2018 Update 3 Build 20180411 (id: 18329)\n",
      "Copyright 2003-2018 Intel Corporation.\n",
      "}\n",
      "2021/01/15 06:07:41 MPI publisher: intel ; version: 2018\n",
      "2021/01/15 06:07:41 Process Exiting with Code:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Streaming azureml-logs/75_job_post-tvmps_254caf111fca5ea9768480baf7421c59a2a87174afc300de44eb1d1f8ee51319_d.txt\n",
      "===============================================================================================================\n",
      "[2021-01-15T06:07:42.552299] Entering job release\n",
      "[2021-01-15T06:07:43.640686] Starting job release\n",
      "[2021-01-15T06:07:43.641630] Logging experiment finalizing status in history service.\n",
      "Starting the daemon thread to refresh tokens in background for process with pid = 1148\n",
      "[2021-01-15T06:07:43.642255] job release stage : upload_datastore starting...\n",
      "[2021-01-15T06:07:43.651496] job release stage : start importing azureml.history._tracking in run_history_release.\n",
      "[2021-01-15T06:07:43.651977] job release stage : copy_batchai_cached_logs starting...\n",
      "[2021-01-15T06:07:43.652296] job release stage : copy_batchai_cached_logs completed...\n",
      "[2021-01-15T06:07:43.652336] job release stage : execute_job_release starting...\n",
      "[2021-01-15T06:07:43.653047] Entering context manager injector.\n",
      "[2021-01-15T06:07:43.868076] job release stage : upload_datastore completed...\n",
      "[2021-01-15T06:07:43.946923] job release stage : execute_job_release completed...\n",
      "[2021-01-15T06:07:43.973360] job release stage : send_run_telemetry starting...\n",
      "[2021-01-15T06:07:44.982460] job release stage : send_run_telemetry completed...\n",
      "[2021-01-15T06:07:44.982742] Job release is complete\n",
      "\n",
      "StepRun(batchscoring-202101151600) Execution Summary\n",
      "=====================================================\n",
      "StepRun( batchscoring-202101151600 ) Status: Failed\n"
     ]
    },
    {
     "ename": "ActivityFailedException",
     "evalue": "ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n        \"messageFormat\": \"{Message}\",\n        \"messageParameters\": {\n            \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n        },\n        \"details\": [],\n        \"innerError\": {\n            \"code\": \"BadArgument\",\n            \"innerError\": {\n                \"code\": \"AmlComputeBadRequest\"\n            }\n        }\n    },\n    \"correlation\": {\n        \"operation\": null,\n        \"request\": \"14c3333c99d0a5c2\"\n    },\n    \"environment\": \"westus2\",\n    \"location\": \"westus2\",\n    \"time\": \"2021-01-15T06:07:55.243737Z\",\n    \"componentName\": \"execution-worker\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\",\\n        \\\"messageFormat\\\": \\\"{Message}\\\",\\n        \\\"messageParameters\\\": {\\n            \\\"Message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\"\\n        },\\n        \\\"details\\\": [],\\n        \\\"innerError\\\": {\\n            \\\"code\\\": \\\"BadArgument\\\",\\n            \\\"innerError\\\": {\\n                \\\"code\\\": \\\"AmlComputeBadRequest\\\"\\n            }\\n        }\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": null,\\n        \\\"request\\\": \\\"14c3333c99d0a5c2\\\"\\n    },\\n    \\\"environment\\\": \\\"westus2\\\",\\n    \\\"location\\\": \\\"westus2\\\",\\n    \\\"time\\\": \\\"2021-01-15T06:07:55.243737Z\\\",\\n    \\\"componentName\\\": \\\"execution-worker\\\"\\n}\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mActivityFailedException\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-4f4581d81259>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpipeline_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpipeline_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Completed in {}s'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    293\u001b[0m                             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                                 step_run.wait_for_completion(timeout_seconds=timeout_seconds - time_elapsed,\n\u001b[0;32m--> 295\u001b[0;31m                                                              raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    296\u001b[0m                             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                                 \u001b[0;31m# If there are package conflicts in the user's environment, the run rehydration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36mwait_for_completion\u001b[0;34m(self, show_output, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    735\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 return self._stream_run_output(timeout_seconds=timeout_seconds,\n\u001b[0;32m--> 737\u001b[0;31m                                                raise_on_error=raise_on_error)\n\u001b[0m\u001b[1;32m    738\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m                 \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"The output streaming for the run interrupted.\\n\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/azureml/pipeline/core/run.py\u001b[0m in \u001b[0;36m_stream_run_output\u001b[0;34m(self, timeout_seconds, raise_on_error)\u001b[0m\n\u001b[1;32m    823\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mraise_on_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mActivityFailedException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mActivityFailedException\u001b[0m: ActivityFailedException:\n\tMessage: Activity Failed:\n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\",\n        \"messageFormat\": \"{Message}\",\n        \"messageParameters\": {\n            \"Message\": \"AzureMLCompute job failed.\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\n\\tReason: Job failed with non-zero exit Code\"\n        },\n        \"details\": [],\n        \"innerError\": {\n            \"code\": \"BadArgument\",\n            \"innerError\": {\n                \"code\": \"AmlComputeBadRequest\"\n            }\n        }\n    },\n    \"correlation\": {\n        \"operation\": null,\n        \"request\": \"14c3333c99d0a5c2\"\n    },\n    \"environment\": \"westus2\",\n    \"location\": \"westus2\",\n    \"time\": \"2021-01-15T06:07:55.243737Z\",\n    \"componentName\": \"execution-worker\"\n}\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"message\": \"Activity Failed:\\n{\\n    \\\"error\\\": {\\n        \\\"code\\\": \\\"UserError\\\",\\n        \\\"message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\",\\n        \\\"messageFormat\\\": \\\"{Message}\\\",\\n        \\\"messageParameters\\\": {\\n            \\\"Message\\\": \\\"AzureMLCompute job failed.\\\\nJobFailed: Submitted script failed with a non-zero exit code; see the driver log file for details.\\\\n\\\\tReason: Job failed with non-zero exit Code\\\"\\n        },\\n        \\\"details\\\": [],\\n        \\\"innerError\\\": {\\n            \\\"code\\\": \\\"BadArgument\\\",\\n            \\\"innerError\\\": {\\n                \\\"code\\\": \\\"AmlComputeBadRequest\\\"\\n            }\\n        }\\n    },\\n    \\\"correlation\\\": {\\n        \\\"operation\\\": null,\\n        \\\"request\\\": \\\"14c3333c99d0a5c2\\\"\\n    },\\n    \\\"environment\\\": \\\"westus2\\\",\\n    \\\"location\\\": \\\"westus2\\\",\\n    \\\"time\\\": \\\"2021-01-15T06:07:55.243737Z\\\",\\n    \\\"componentName\\\": \\\"execution-worker\\\"\\n}\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "pipeline_run = Experiment(ws, experiment_name).submit(pipeline)\n",
    "print(pipeline_run)\n",
    "pipeline_run.wait_for_completion(show_output=True)\n",
    "print('Completed in {}'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish pipeline as a REST endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=experiment_name, description=\"Batching scoring\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a job via REST endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name,\n",
    "                               \"ParameterAssignments\": {\"model_name\": model_name}})\n",
    "try:\n",
    "    response.raise_for_status()\n",
    "except Exception:    \n",
    "    raise Exception(\"Received bad response from the endpoint: {}\\n\"\n",
    "                    \"Response Code: {}\\n\"\n",
    "                    \"Headers: {}\\n\"\n",
    "                    \"Content: {}\".format(rest_endpoint, response.status_code, response.headers, response.content))\n",
    "\n",
    "run_id = response.json().get('Id')\n",
    "print('Submitted pipeline run: ', run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
