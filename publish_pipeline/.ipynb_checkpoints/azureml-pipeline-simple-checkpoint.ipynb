{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure Machine Learning Service example\n",
    "### Deploy and publish batch scoring pipeline\n",
    "\n",
    "*This notebook shows you how to:*\n",
    "- Create a batch scoring dummy experiment\n",
    "- Publish the experiment as a pipeline\n",
    "- Deploy the pipelie as a web service with HTTP endpoint (asynchronous API)\n",
    "- Submit a job request via the HTTP endpoint with basic authentication\n",
    "\n",
    "These is another similar [tutorial](https://docs.microsoft.com/en-us/azure/machine-learning/tutorial-pipeline-batch-scoring-classification) published in Microsoft documentation.  \n",
    "\n",
    "Difference between the existing batch scoring example and this example:\n",
    "\n",
    "- This version focus in demonstrating the code for the pipeline and uses dummy dataset and a dummy model instead of a real model.  \n",
    "- It is much easier to register and configure the assets (e.g. Dataset, Compute) through the Azure Machine Learning Service web interface, so the assumption is that they have already been created and the pipeline code will use **get** instead of **register** to get references to those assets in your workspace.\n",
    "- This pipeline uses *PythonScriptStep* (no mini-batching) instead of *ParallelRunConfig* and *ParallelRunStep*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup workspace\n",
    "- Workspace created in Azure Machine Learning service - [howto](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-manage-workspace?tabs=python)\n",
    "- Updated the cell below with your workspace details and run the cell to connect to workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "config_file = '_config.json'\n",
    "\n",
    "subscription_id='xxxxx' # Subscription ID of the workspace\n",
    "resource_group='xxxxx' # Resource group of the workspace\n",
    "workspace_name = \"xxxxxx\" # Name of your workspace\n",
    "\n",
    "if os.path.isfile(config_file):\n",
    "    with open(config_file, 'r') as f:\n",
    "        configs = json.load(f)\n",
    "        subscription_id = configs['subscription_id']\n",
    "        resource_group = configs['resource_group']\n",
    "        workspace_name = configs['workspace_name']\n",
    "\n",
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.get(name=workspace_name,\n",
    "               subscription_id=subscription_id,\n",
    "               resource_group=resource_group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise\n",
    "- Updated the asset names in the cell below (optional)\n",
    "- Execute to initialise variables, create temp directory for storing files for upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 1.20.0\n"
     ]
    }
   ],
   "source": [
    "# Asset names \n",
    "model_dir = 'simple_model'\n",
    "model_name = model_dir\n",
    "model_file = 'model_v{}.json'\n",
    "experiment_name = \"pipeline_simple\"\n",
    "compute_name = \"DS3-4c-14G\"\n",
    "environment_name = \"test_minimal\"\n",
    "dataset_parent_path = \"data\"\n",
    "dataset_name = experiment_name\n",
    "\n",
    "# Temp local directory for storing created files that will be uploaded to AML for the pipeline\n",
    "local_temp_dir = './_temp'\n",
    "\n",
    "import os \n",
    "local_path_to_model = os.path.join(local_temp_dir, model_dir)\n",
    "if not os.path.isdir(local_path_to_model):\n",
    "    os.makedirs(local_path_to_model)\n",
    "    \n",
    "import azureml.core\n",
    "print(\"SDK version:\", azureml.core.VERSION)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Dataset\n",
    "1. Generate sample input dataset csv file by executing the next cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./_temp/pipeline_simple_input.csv\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./_temp/pipeline_simple_input.csv\n",
    "id,gender,age\n",
    "1,F,30\n",
    "2,F,50\n",
    "3,M,55\n",
    "4,M,23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use the Azure ML web interface to register the dataset\n",
    "    - Load your AML workspace in the web browser\n",
    "    - Click on 'Dataset' option\n",
    "    - Use the register action to register this input csv as a dataset in your workspace, use the name 'pipeline_simple' as the dataset name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get reference to input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.dataset import Dataset \n",
    "input_data = Dataset.get_by_name(ws, dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and register model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age_average': 40}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Create model\n",
    "class MyModel:\n",
    "    \n",
    "    def load_model(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            loaded_params = json.load(f)\n",
    "            return MyModel(loaded_params)\n",
    "    \n",
    "    def __init__(self, params):\n",
    "        self._params = params\n",
    "    \n",
    "    def predict(self, data):\n",
    "        data['prediction'] = data.age < self._params['age_average']\n",
    "        return data[['id', 'prediction']]\n",
    "\n",
    "    \n",
    "\n",
    "params = {'age_average':40}\n",
    "local_model_path = os.path.join(local_path_to_model, model_file)\n",
    "\n",
    "with open(local_model_path, 'w') as f:\n",
    "    json.dump(params, f)\n",
    "# Test model code\n",
    "mymodel = MyModel.load_model(local_model_path)\n",
    "print(str(mymodel._params))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get compute target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import AmlCompute, ComputeTarget\n",
    "from azureml.exceptions import ComputeTargetException\n",
    "\n",
    "# checks to see if compute target already exists in workspace, else create it\n",
    "try:\n",
    "    compute_target = ComputeTarget(workspace=ws, name=compute_name)\n",
    "except ComputeTargetException as e:\n",
    "    config = AmlCompute.provisioning_configuration(vm_size=\"STANDARD_NC6\",\n",
    "                                                   vm_priority=\"lowpriority\", \n",
    "                                                   min_nodes=0, \n",
    "                                                   max_nodes=1)\n",
    "\n",
    "    compute_target = ComputeTarget.create(workspace=ws, name=compute_name, provisioning_configuration=config)\n",
    "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define environment\n",
    "- Create requirements file with dependencies require for running your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./_temp/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./_temp/requirements.txt\n",
    "pandas\n",
    "numpy\n",
    "azureml-core\n",
    "azureml-dataset-runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "# Pipeline doesn't like using curated environment, create a new one \n",
    "env = Environment.from_pip_requirements(name = environment_name, file_path = os.path.join(local_temp_dir, 'requirements.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build & run pipeline\n",
    "#### 1. Create scoring file\n",
    "This is a python script for making prediction based on your model.  This [section](https://docs.microsoft.com/en-au/azure/machine-learning/how-to-deploy-existing-model#entry-script-scorepy) in Azure documentation explains how this file works.  Note how this scoring script uses azureml.core modules, hence we need the azureml-core azure-datatime-runtime included as dependencies when defining the environment previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ./_temp/batch_scoring.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./_temp/batch_scoring.py\n",
    "\n",
    "from azureml.core import Run\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.dataset import Dataset\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    \n",
    "    class MyModel:\n",
    "\n",
    "        def load_model(file_path):\n",
    "            with open(file_path, 'r') as f:\n",
    "                loaded_params = json.load(f)\n",
    "                return MyModel(loaded_params)\n",
    "\n",
    "        def __init__(self, params):\n",
    "            self._params = params\n",
    "\n",
    "        def predict(self, data):\n",
    "            data['prediction'] = data.age < self._params['age_average']\n",
    "            return data[['id', 'prediction']]\n",
    "        \n",
    "    # Read from parameters from argument, e.g. which model to use\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--model_name', dest=\"model_name\", required=True)\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    \n",
    "    model_dir = 'simple_model'\n",
    "    model_name = args.model_name\n",
    "    print(str(datetime.now()) + ': init()')\n",
    "    # Get the path where the deployed model can be found.\n",
    "    print('model_name=' + str(model_name))\n",
    "    \n",
    "    #model_path = os.path.join(os.getenv('AZUREML_MODEL_DIR'), model_name)\n",
    "    model_path = Model.get_model_path(model_dir) + '/' + model_name + '.json'\n",
    "    print('model_path=' + model_path)\n",
    "    print('found_model_file=' + str(os.path.isfile(model_path)))\n",
    "    model = MyModel.load_model(model_path)\n",
    "    print(str(datetime.now()) + ': Model loaded')\n",
    "\n",
    "\n",
    "def run(data):\n",
    "    print(str(datetime.now()) + ': run()')\n",
    "    output = model.predict(data)\n",
    "    print(str(datetime.now()) + ': run completed()')\n",
    "    return output\n",
    "\n",
    "def local_test():\n",
    "    init()\n",
    "    input_data = pd.read_csv(os.path.join('_temp/pipeline_simple_input.csv'))\n",
    "    print(run(input_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define the pipeline\n",
    "- Here, we are building a pipeline with only one step.  A pipeline can contain multiple steps that perform post-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/azureml/pipeline/core/_parallel_run_step_base.py:508: UserWarning: \n",
      "ParallelRunStep requires azureml-dataset-runtime[fuse,pandas] for tabular dataset.\n",
      "Please add relevant package in CondaDependencies.\n",
      "  Please add relevant package in CondaDependencies.\"\"\".format(extra, self._input_ds_type), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Datastore\n",
    "from azureml.core import Experiment\n",
    "from azureml.pipeline.core import Pipeline, PipelineParameter\n",
    "\n",
    "def_data_store = Datastore.get_default(ws)\n",
    "\n",
    "def parallel_run_step():\n",
    "    from azureml.pipeline.steps import ParallelRunConfig\n",
    "    from azureml.pipeline.core import PipelineData\n",
    "\n",
    "    parallel_run_config = ParallelRunConfig(\n",
    "        environment=env,\n",
    "        entry_script=os.path.join(local_temp_dir, \"batch_scoring.py\"),\n",
    "        source_directory=\".\",\n",
    "        output_action=\"append_row\",\n",
    "        append_row_file_name=\"parallel_run_step.txt\",\n",
    "        compute_target=compute_target,\n",
    "        error_threshold=1,\n",
    "        node_count=1,\n",
    "        process_count_per_node=2\n",
    "    )\n",
    "\n",
    "    from azureml.pipeline.steps import ParallelRunStep\n",
    "    from datetime import datetime\n",
    "\n",
    "    parallel_step_name = \"batchscoring-\" + datetime.now().strftime(\"%Y%m%d%H%M\")\n",
    "    output_dir = PipelineData(name=dataset_name, datastore=def_data_store)\n",
    "    model_name_param = PipelineParameter(name=\"model_arg\", default_value=model_name)\n",
    "\n",
    "    batch_score_step = ParallelRunStep(\n",
    "        name=parallel_step_name,\n",
    "        inputs=[input_data.as_named_input(\"input\")],\n",
    "        output=output_dir,\n",
    "        arguments=[\"--model_name\", model_name_param],\n",
    "        parallel_run_config=parallel_run_config,\n",
    "        allow_reuse=False\n",
    "    )\n",
    "    return batch_score_step\n",
    "    \n",
    "batch_score_step = parallel_run_step()\n",
    "pipeline = Pipeline(workspace=ws, steps=[batch_score_step])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Submit the pipeline as an experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created step batchscoring-202101151600 [7d1d18b8][6cf11253-38c3-4064-8892-1fc492853955], (This step will run and generate new outputs)\n",
      "Submitted PipelineRun 0fc7480b-06ae-4643-a05f-d8e9ad0d18c7\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "pipeline_run = Experiment(ws, experiment_name).submit(pipeline)\n",
    "print(pipeline_run)\n",
    "pipeline_run.wait_for_completion(show_output=True)\n",
    "print('Completed in {}'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish pipeline as a REST endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "published_pipeline = pipeline_run.publish_pipeline(\n",
    "    name=experiment_name, description=\"Batching scoring\", version=\"1.0\")\n",
    "\n",
    "published_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a job via REST endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.authentication import InteractiveLoginAuthentication\n",
    "\n",
    "interactive_auth = InteractiveLoginAuthentication()\n",
    "auth_header = interactive_auth.get_authentication_header()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "rest_endpoint = published_pipeline.endpoint\n",
    "response = requests.post(rest_endpoint, \n",
    "                         headers=auth_header, \n",
    "                         json={\"ExperimentName\": experiment_name,\n",
    "                               \"ParameterAssignments\": {\"model_name\": 6}})\n",
    "try:\n",
    "    response.raise_for_status()\n",
    "except Exception:    \n",
    "    raise Exception(\"Received bad response from the endpoint: {}\\n\"\n",
    "                    \"Response Code: {}\\n\"\n",
    "                    \"Headers: {}\\n\"\n",
    "                    \"Content: {}\".format(rest_endpoint, response.status_code, response.headers, response.content))\n",
    "\n",
    "run_id = response.json().get('Id')\n",
    "print('Submitted pipeline run: ', run_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
